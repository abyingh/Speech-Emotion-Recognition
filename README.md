In this project, **cross-linguistic speech emotion recognition** is aimed. For this purpose, emotional data of different languages (English, Lithuanian, German, Spanish, Serbian, and Polish) are used, and the formats of the collected utterances were *WAV*. Then, the feature extraction process were performed. A few two-dimensional feature spaces such as **cochleagrams, spectrograms, mel cepstrograms, and fractal dimension-based space** are employed as emotional features of the speech. A CNN framework built with Keras is used as a decision system.
